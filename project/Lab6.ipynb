{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Background:\n",
    "Creation of a table of peak pairs from a song or clip.\n",
    "Use of these tables to form a searchable database.\n",
    "\n",
    "2. Finding a Clip Match:\n",
    "Generating a clip table from the input clip.\n",
    "Searching the database for matching entries.\n",
    "Using hash functions to facilitate fast lookup.\n",
    "Determining the song with the most matches.\n",
    "\n",
    "3. Noise and SNR:\n",
    "Adding noise to clips and measuring the classification performance at different SNRs.\n",
    "Evaluating the system's robustness by varying noise levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Important Points\n",
    "\n",
    "1. Hash Table Construction:\n",
    "Each entry in the song table is hashed based on its frequencies and time differences.\n",
    "Handling collisions in the hash table is necessary for accurate matching.\n",
    "\n",
    "2. Clip Matching:\n",
    "Matches are found by identifying common time differences in peak pairs.\n",
    "A histogram of these differences helps determine the correct song.\n",
    "\n",
    "3. Performance Testing:\n",
    "Performance is tested by adding Gaussian noise to clips and measuring the correct classification rate.\n",
    "The effect of clip length on classification accuracy is also assessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CantinaBand3.wav': True, 'CantinaBand60.wav': True, 'filtered_PinkPanther60.wav': True, 'filtered_whkight.wav': True, 'PinkPanther60.wav': True, 'pure_tone.wav': True, 'simple_signal.wav': True, 'sound.wav': True, 'StarWars60.wav': True, 'taunt.wav': True, 'tel.wav': True, 'temp_clip.wav': True, 'whkight.wav': True}\n",
      "Processing CantinaBand3.wav...\n",
      "Processing CantinaBand60.wav...\n",
      "Processing filtered_PinkPanther60.wav...\n",
      "Processing filtered_whkight.wav...\n",
      "Processing PinkPanther60.wav...\n",
      "Processing pure_tone.wav...\n",
      "Processing simple_signal.wav...\n",
      "Processing sound.wav...\n",
      "Processing StarWars60.wav...\n",
      "Processing taunt.wav...\n",
      "Processing tel.wav...\n",
      "Processing temp_clip.wav...\n",
      "Processing whkight.wav...\n",
      "Looking for file at: C:\\Users\\DHANASHRI\\Downloads\\StarWars3.wav\n",
      "StarWars60.wav\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "import hashlib\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Hash table and song list initialization\n",
    "HASH_TABLE = {}\n",
    "SONG_LIST = []\n",
    "\n",
    "# Utility functions\n",
    "def hash_function(f1, f2, dt):\n",
    "    dt_int = int(dt * 1000)  # Scale dt to milliseconds and convert to int\n",
    "    return (dt_int << 16) + (f1 << 8) + f2\n",
    "\n",
    "def add_to_hash(song_id, table):\n",
    "    global HASH_TABLE\n",
    "    for f1, f2, t1, dt in table:\n",
    "        h = hash_function(f1, f2, dt)\n",
    "        if h not in HASH_TABLE:\n",
    "            HASH_TABLE[h] = []\n",
    "        HASH_TABLE[h].append((song_id, t1))\n",
    "\n",
    "def save_database():\n",
    "    with open('HASHTABLE.pkl', 'wb') as f:\n",
    "        pickle.dump(HASH_TABLE, f)\n",
    "    with open('SONGID.pkl', 'wb') as f:\n",
    "        pickle.dump(SONG_LIST, f)\n",
    "\n",
    "def load_database():\n",
    "    global HASH_TABLE, SONG_LIST\n",
    "    with open('HASHTABLE.pkl', 'rb') as f:\n",
    "        HASH_TABLE = pickle.load(f)\n",
    "    with open('SONGID.pkl', 'rb') as f:\n",
    "        SONG_LIST = pickle.load(f)\n",
    "\n",
    "def make_table(audio, fs, peak_count=100):\n",
    "    peaks, _ = find_peaks(audio, height=0)\n",
    "    if len(peaks) > peak_count:\n",
    "        peaks = peaks[:peak_count]  # Limit the number of peaks to avoid excessive combinations\n",
    "    table = []\n",
    "    for i in range(len(peaks) - 1):\n",
    "        for j in range(i + 1, len(peaks)):\n",
    "            f1 = peaks[i]\n",
    "            f2 = peaks[j]\n",
    "            t1 = peaks[i] / fs\n",
    "            t2 = peaks[j] / fs\n",
    "            dt = t2 - t1\n",
    "            table.append((f1, f2, t1, dt))\n",
    "    return table\n",
    "\n",
    "def add_songs_to_database(directory='.'):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.wav'):\n",
    "            print(f\"Processing {file}...\")\n",
    "            fs, data = wavfile.read(os.path.join(directory, file))\n",
    "            song_id = len(SONG_LIST)\n",
    "            SONG_LIST.append(file)\n",
    "            table = make_table(data, fs)\n",
    "            add_to_hash(song_id, table)\n",
    "    save_database()\n",
    "\n",
    "def myshazam(clip_file, test_directory='.'):\n",
    "    load_database()\n",
    "    test_file_path = os.path.join(test_directory, clip_file)\n",
    "    print(f\"Looking for file at: {os.path.abspath(test_file_path)}\")  # Print the absolute path for debugging\n",
    "    if not os.path.isfile(test_file_path):\n",
    "        return f\"File not found: {test_file_path}\"\n",
    "    fs, clip_data = wavfile.read(test_file_path)\n",
    "    clip_table = make_table(clip_data, fs)\n",
    "    match_counts = {}\n",
    "    for f1, f2, t1, dt in clip_table:\n",
    "        h = hash_function(f1, f2, dt)\n",
    "        if h in HASH_TABLE:\n",
    "            for song_id, ts1 in HASH_TABLE[h]:\n",
    "                offset = ts1 - t1\n",
    "                if song_id not in match_counts:\n",
    "                    match_counts[song_id] = []\n",
    "                match_counts[song_id].append(offset)\n",
    "    best_match = max(match_counts, key=lambda k: len(match_counts[k]), default=None)\n",
    "    if best_match is not None:\n",
    "        return SONG_LIST[best_match]\n",
    "    else:\n",
    "        return \"No match found\"\n",
    "\n",
    "def test_minimum_duration(directory='.', min_duration_sec=1):\n",
    "    results = {}\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.wav'):\n",
    "            fs, data = wavfile.read(os.path.join(directory, file))\n",
    "            duration = len(data) / fs\n",
    "            results[file] = duration >= min_duration_sec\n",
    "    return results\n",
    "\n",
    "# Determine the minimum duration\n",
    "min_duration_sec = 1  # Set this to the duration you want to test\n",
    "duration_results = test_minimum_duration('.', min_duration_sec)\n",
    "print(duration_results)\n",
    "\n",
    "# Sample usage\n",
    "# Ensure your .wav files are in the same directory as this Jupyter notebook\n",
    "add_songs_to_database('.')\n",
    "print(myshazam('StarWars3.wav', 'C:\\\\Users\\\\DHANASHRI\\\\Downloads'))  # Replace 'StarWars3.wav' with your test clip file name\n",
    "\n",
    "# Test performance with noise\n",
    "snr_db_list = [-15, -12, -9, -6, -3, 0, 3, 6, 9, 12, 15]\n",
    "# performance_results = test_performance_with_noise('.', snr_db_list, 10)\n",
    "# print(performance_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg-pythonNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting future (from ffmpeg-python)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "   ---------------------------------------- 0.0/491.3 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 51.2/491.3 kB 890.4 kB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 122.9/491.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 235.5/491.3 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 450.6/491.3 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 491.3/491.3 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: future, ffmpeg-python\n",
      "Successfully installed ffmpeg-python-0.2.0 future-1.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement os (from versions: none)\n",
      "ERROR: No matching distribution found for os\n"
     ]
    }
   ],
   "source": [
    "pip install os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement random (from versions: none)\n",
      "ERROR: No matching distribution found for random\n"
     ]
    }
   ],
   "source": [
    "pip install random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n"
     ]
    }
   ],
   "source": [
    "pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following yanked versions: 20081119\n",
      "ERROR: Could not find a version that satisfies the requirement hashlib (from versions: none)\n",
      "ERROR: No matching distribution found for hashlib\n"
     ]
    }
   ],
   "source": [
    "pip install hashlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
